adzuna_summary = get_completion(
"Dear Chat GPT, could you please conduct the following actions on the test in square brackets: Identify all skills, characteristics and qualifications required for the job and return them as itemized points in English. Split those into individual skills (e.g. phrase 'SQL, Excel, and Power BI' should produce three items on the list you return: 'SQL', 'Excel', 'Power BI'). Please do not return any text other than the requirements, please! Please provide your answer as a Python list [" + adzuna_description +"]"
)
print(adzuna_summary)
adzuna_summary = get_completion(
"Dear Chat GPT, could you please conduct the following actions on the test in square brackets: Identify all skills, characteristics and qualifications required for the job and return them as itemized points in English. Split those into individual skills (e.g. phrase 'SQL, Excel, and Power BI' should produce three items on the list you return: 'SQL', 'Excel', 'Power BI'). Please do not return any text other than the requirements, please! Please provide your answer, including the soft skills, as a Python list [" + adzuna_description +"]"
)
print(adzuna_summary)
adzuna_summary = get_completion(
"Dear Chat GPT, could you please conduct the following actions on the test in square brackets: Identify all skills, characteristics and qualifications required for the job and return them as itemized points in English. Split those into individual skills (e.g. phrase 'SQL, Excel, and Power BI' should produce three items on the list you return: 'SQL', 'Excel', 'Power BI'). Group into soft skills and technical skills. Please do not return any text other than the requirements, please! [" + adzuna_description +"]"
)
print(adzuna_summary)
adzuna_summary = get_completion(
"Dear Chat GPT, could you please conduct the following actions on the test in square brackets: Identify all skills, characteristics and qualifications required for the job and return them as itemized points in English. Split those into individual skills (e.g. phrase 'SQL, Excel, and Power BI' should produce three items on the list you return: 'SQL', 'Excel', 'Power BI'). Group into soft skills, technical skills and qualifications. Provide the return in JSON format please! [" + adzuna_description +"]"
)
print(adzuna_summary)
adzuna_summary = get_completion(
"Dear Chat GPT, could you please conduct the following actions on the test in square brackets: Identify all skills, characteristics and qualifications required for the job and return them as itemized points in English. Split those into individual skills (e.g. phrase 'SQL, Excel, and Power BI' should produce three items on the list you return: 'SQL', 'Excel', 'Power BI'). Group into soft skills, technical skills and qualifications. Integrate any optional skills/qualifications into one of the three categories (soft skills, technical skills, and qualifications). Provide the return in JSON format please! [" + adzuna_description +"]"
)
print(adzuna_summary)
adzuna_summary = get_completion(
"Dear Chat GPT, could you please conduct the following actions on the test in square brackets: Identify all skills, characteristics and qualifications required for the job and return them as itemized points in English. Split those into individual skills (e.g. phrase 'SQL, Excel, and Power BI' should produce three items on the list you return: 'SQL', 'Excel', 'Power BI'). Group into soft skills, technical skills and qualifications (and no other categories). Provide the return in JSON format please! [" + adzuna_description +"]"
)
print(adzuna_summary)
### Now lets pass a job description to Chat GPT and build a prompt
adzuna_description = r.test3
print(adzuna_description)
adzuna_summary = get_completion(
"Dear Chat GPT, could you please conduct the following actions on the test in square brackets: Identify all skills, characteristics and qualifications required for the job and return them as itemized points in English. Split those into individual skills (e.g. phrase 'SQL, Excel, and Power BI' should produce three items on the list you return: 'SQL', 'Excel', 'Power BI'). Group into soft skills, technical skills and qualifications. Provide the return in JSON format please! [" + adzuna_description +"]"
)
print(adzuna_summary)
adzuna_summary = get_completion(
"Dear Chat GPT, could you please conduct the following actions on the test in square brackets: Identify all skills, characteristics and qualifications required for the job and return them as itemized points in English. Split those into individual skills (e.g. phrase 'SQL, Excel, and Power BI' should produce three items on the list you return: 'SQL', 'Excel', 'Power BI'). Group into soft skills, technical skills and qualifications. Provide the return in JSON format please! [" + adzuna_description +"]"
)
print(adzuna_summary)
### Now lets pass a job description to Chat GPT and build a prompt
adzuna_description = r.test3
print(adzuna_description)
adzuna_summary = get_completion(
"Dear Chat GPT, could you please conduct the following actions on the test in square brackets: Identify all skills, characteristics and qualifications required for the job and return them as itemized points in English. Split those into individual skills (e.g. phrase 'SQL, Excel, and Power BI' should produce three items on the list you return: 'SQL', 'Excel', 'Power BI'). Group into soft skills, technical skills and qualifications. Provide the return in JSON format please! [" + adzuna_description +"]"
)
print(adzuna_summary)
adzuna_summary = get_completion(
"Dear Chat GPT, could you please conduct the following actions on the test in square brackets: Identify all skills, characteristics and qualifications required for the job and return them as itemized points in English. Split those into individual skills. Group into soft skills, technical skills and qualifications. Provide the return in JSON format please! [" + adzuna_description +"]"
)
print(adzuna_summary)
### Now lets pass a job description to Chat GPT and build a prompt
adzuna_description = r.test3
print(adzuna_description)
adzuna_summary = get_completion(
"Dear Chat GPT, could you please conduct the following actions on the test in square brackets: Identify all skills, characteristics and qualifications required for the job and return them as itemized points in English. Split those into individual skills. Group into soft skills, technical skills and qualifications. Provide the return in JSON format please! [" + adzuna_description +"]"
)
print(adzuna_summary)
library(httr)
library(tidyverse)
library(jsonlite)
library(rvest)
library(reticulate)
##This chunk is concerned with getting the API function working
## Write a function to get any given page. After that I can just iterate while there are still jobs to find :)
get_adzuna_api <- function(api_id, api_key, page,
key_words = c("data", "analyst"), country = "ch") { #API ID and key are variables, so that they can remain secret
key_words <- stringr::str_c(key_words[1], "%20", key_words[2]) #Can only take two key words. All needed for most data professions
api_call_string <- stringr::str_c("http://api.adzuna.com/v1/api/jobs/",
country, "/search/", page, "?app_id=",
api_id, "&app_key=", api_key,
"&results_per_page=20&what=", key_words,
"&max_days_old=730&salary_include_unknown=1&content-type=application/json")
api_return <- GET(api_call_string)
api_return_text <- content(api_return, "text")
api_return_df <- jsonlite::fromJSON(api_return_text)
api_return_df$results
}
n_responses <- 20
page <- 1
adzuna_api_returns_raw_13jul23 <- data.frame()
while (n_responses > 0) {
current_response <- get_adzuna_api(
readLines("/home/pete/Documents/adzuna_api.txt")[1],
readLines("/home/pete/Documents/adzuna_api.txt")[2], page) ##Run the API.
adzuna_api_returns_raw_13jul23 <- rbind(adzuna_api_returns_raw_13jul23,
current_response) ## Bind to general results table.
page <- page + 1 #Increase the page number.
n_responses <-nrow(current_response) ## Check response count for the purposes of running the loop.
Sys.sleep(3) ##This is to make sure that we do not hit the 25 hits per minute limit on the API.
}
View(current_response)
View(adzuna_api_returns_raw_13jul23)
library(httr)
library(tidyverse)
library(jsonlite)
library(rvest)
library(reticulate)
##This chunk is concerned with getting the API function working
## Write a function to get any given page. After that I can just iterate while there are still jobs to find :)
get_adzuna_api <- function(api_id, api_key, page,
key_words = c("data", "analyst"), country = "ch") { #API ID and key are variables, so that they can remain secret
key_words <- stringr::str_c(key_words[1], "%20", key_words[2]) #Can only take two key words. All needed for most data professions
api_call_string <- stringr::str_c("http://api.adzuna.com/v1/api/jobs/",
country, "/search/", page, "?app_id=",
api_id, "&app_key=", api_key,
"&results_per_page=20&what=", key_words,
"&max_days_old=730&salary_include_unknown=1&content-type=application/json")
api_return <- GET(api_call_string)
api_return_text <- content(api_return, "text")
api_return_df <- jsonlite::fromJSON(api_return_text)
api_return_df$results
}
## This code block is about removing unwanted columns from the APi response and renaming other ones.
## Functionalizing for easier integration into the automated pipeline downstream
clean_adzuna_response <- function(adzuna_response) {
response_cleaned <- data.frame(
date_posted = adzuna_response$created,
job_title = adzuna_response$title,
company = adzuna_response$company$display_name,
location = adzuna_response$location$display_name,
website = adzuna_response$redirect_url
) %>%
filter(str_detect(website, "details")) #Adzuna links quite a few instances of external job boards
response_cleaned
}
n_responses <- 20 ## Lets not turn off the loop before we start
page <- 1 ## Start at page 1
adzuna_api_returns_14jul23 <- data.frame()  ##Take note of date when responses collected
while (n_responses > 0) {
current_response <- get_adzuna_api(
readLines("/home/pete/Documents/adzuna_api.txt")[1],
readLines("/home/pete/Documents/adzuna_api.txt")[2], page) ##Run the API.
page <- page + 1 #Increase the page number.
n_responses <-nrow(current_response) ## Check response count for the purposes of running the loop.
current_response <- clean_adzuna_response(current_response) ## Different API returns give different numbers of columns. This should standardize and prevent crashes.
adzuna_api_returns_13jul23 <- rbind(adzuna_api_returns_raw_14jul23,
current_response) ## Bind to general results table.
Sys.sleep(3) ##This is to make sure that we do not hit the 25 hits per minute limit on the API.
}
n_responses <- 20 ## Lets not turn off the loop before we start
page <- 1 ## Start at page 1
adzuna_api_returns_14jul23 <- data.frame()  ##Take note of date when responses collected
while (n_responses > 0) {
current_response <- get_adzuna_api(
readLines("/home/pete/Documents/adzuna_api.txt")[1],
readLines("/home/pete/Documents/adzuna_api.txt")[2], page) ##Run the API.
page <- page + 1 #Increase the page number.
n_responses <-nrow(current_response) ## Check response count for the purposes of running the loop.
current_response <- clean_adzuna_response(current_response) ## Different API returns give different numbers of columns. This should standardize and prevent crashes.
adzuna_api_returns_14jul23 <- rbind(adzuna_api_returns_14jul23,
current_response) ## Bind to general results table.
Sys.sleep(3) ##This is to make sure that we do not hit the 25 hits per minute limit on the API.
}
write_rds(adzuna_api_returns_14jul23, "adzuna_api_returns_14jul23.rds")
### At first, this will be a mess of re-learning how to web scrape :P
parse_adzuna_data <- function (adzuna_http){
adzuna_html_response <- read_html(adzuna_http) #Get the website
adzuna_body <- adzuna_html_response %>% #Extract the body of the job ad
html_nodes(".adp-body") %>%
html_text()
adzuna_body
}
reticulate::repl_python()
##Lets get a URL to visit
test2 <- read_csv("test_returns.csv")
test2$website[4]
##Get a return to work with for dev
test3 <- parse_adzuna_data(test2$website[2])
test3
reticulate::repl_python()
python_call <- str_c("summarize_aduna(r.", test3, ")")
python_call <- str_c("summarize_adzuna(r.", "test3", ")")
python_call <- str_c("summarize_adzuna(r.", "test3", ")")
py_run_string(python_call)
test5 <- py_run_string(python_call)
View(test5)
test5 <- py.summarize_adzuna(python_call)
reticulate::repl_python()
py_call("py_check")
py_call(py_check)
py_eval("x = 10")
py_eval(x = 10)
py$py_check
py$summarize_adzuna(r.test3)
py$summarize_adzuna()
py$summarize_adzuna(test3)
execute_scrape_and_prompt <- function (adzuna_address){
adzuna_raw_return <- parse_adzuna_data(adzuna_address)
py$summarize_adzuna(adzuna_raw_return)
}
test5 <- execute_scrape_and_prompt(adzuna_api_returns_14jul23$website[1])
test5
fromJSON(test5)
list("test")
check <- list("test")
append(check, "test2")
job_details <- list()
for (i in 1:5) {
json_return <- execute_scrape_and_prompt(adzuna_api_returns_14jul23$website[i])
job_details <- append(job_details, fromJSON(raw_return))
Sys.sleep(20) ## Given the time to webscrape and call GPT this should be redundant... but I do not feel like getting blocked from either.
}
job_details <- list()
for (i in 1:5) {
json_return <- execute_scrape_and_prompt(adzuna_api_returns_14jul23$website[i])
job_details <- append(job_details, fromJSON(json_return))
Sys.sleep(20) ## Given the time to webscrape and call GPT this should be redundant... but I do not feel like getting blocked from either.
}
job_details
adzuna_api_returns_14jul23$website[1]
job_details <- list()
for (i in 1:nrow(adzuna_api_returns_14jul23)) {
json_return <- execute_scrape_and_prompt(adzuna_api_returns_14jul23$website[i])
job_details <- append(job_details, fromJSON(json_return))
Sys.sleep(20) ## Given the time to webscrape and call GPT this should be redundant... but lets be polite.
}
adzuna_api_returns_14jul23$website[i]
json_return
log("a")
try(log("a"))
try(log("a"))
library(httr)
library(tidyverse)
library(jsonlite)
library(rvest)
library(reticulate)
for (i in 1:10) {
log("a")
}
for (i in 1:10) {
try(log("a"))
}
for (i in 1:10) {
try(
log("a"),
1+1
)
}
for (i in 1:10) {
try(
log("a"),
1
)
}
for (i in 1:10) {
try(
log("a")
)
}
for (i in 1:10) {
try({
log("a")
)
for (i in 1:10) {
try({
log("a")
1+1
})
}
for (i in 1:10) {
try({
log("a", silent = TRUE)
1+i
})
}
for (i in 1:10) {
try({
log("a")
1+i
}, silent = TRUE)
}
##This chunk is concerned with getting the API function working
## Write a function to get any given page. After that I can just iterate while there are still jobs to find :)
get_adzuna_api <- function(api_id, api_key, page,
key_words = c("data", "analyst"), country = "ch") { #API ID and key are variables, so that they can remain secret
key_words <- stringr::str_c(key_words[1], "%20", key_words[2]) #Can only take two key words. All needed for most data professions
api_call_string <- stringr::str_c("http://api.adzuna.com/v1/api/jobs/",
country, "/search/", page, "?app_id=",
api_id, "&app_key=", api_key,
"&results_per_page=20&what=", key_words,
"&max_days_old=730&salary_include_unknown=1&content-type=application/json")
api_return <- GET(api_call_string)
api_return_text <- content(api_return, "text")
api_return_df <- jsonlite::fromJSON(api_return_text)
api_return_df$results
}
## This code block is about removing unwanted columns from the APi response and renaming other ones.
## Functionalizing for easier integration into the automated pipeline downstream
clean_adzuna_response <- function(adzuna_response) {
response_cleaned <- data.frame(
date_posted = adzuna_response$created,
job_title = adzuna_response$title,
company = adzuna_response$company$display_name,
location = adzuna_response$location$display_name,
website = adzuna_response$redirect_url
) %>%
filter(str_detect(website, "details")) #Adzuna links quite a few instances of external job boards
response_cleaned
}
### At first, this will be a mess of re-learning how to web scrape :P
parse_adzuna_data <- function (adzuna_http){
adzuna_html_response <- read_html(adzuna_http) #Get the website
adzuna_body <- adzuna_html_response %>% #Extract the body of the job ad
html_nodes(".adp-body") %>%
html_text()
adzuna_body
}
reticulate::repl_python()
execute_scrape_and_prompt <- function (adzuna_address){
adzuna_raw_return <- parse_adzuna_data(adzuna_address)
py$summarize_adzuna(adzuna_raw_return) ## The py$ calls from the python side of the environment
}
adzuna_api_returns_14jul23 <- readRDS("adzuna_api_returns_14jul23.rds")
job_details <- list()
for (i in 1:nrow(adzuna_api_returns_14jul23)) {
try({   ###The try function is here in case any web scrape fails
json_return <- execute_scrape_and_prompt(
adzuna_api_returns_14jul23$website[i])
job_details <- append(job_details, fromJSON(json_return))
}, silent = TRUE
)
Sys.sleep(30) ## Given the time to webscrape and call GPT this should be redundant... but lets be polite.
}
View(job_details)
write_rds(job_details, "job_details_14jul23.rds")
library(httr)
library(tidyverse)
library(jsonlite)
library(rvest)
library(reticulate)
json_results <- readRDS("job_details_14jul23.rds")
job_details <- as_tibble(json_results)
job_details <- fromJSON(json_results)
job_details <- toJSON(json_results)
json_results[1]
json_results[1][1]
json_results[[1]]
json_results[[1]][2]
json_results[[1]][[2]]
json_results[["skills"]]
json_results["skills"]
unlist(json_results)
flatten(json_results)
map_chr(l, "technical skills")
map_chr(json_results, "technical skills")
map_chr(json_results, "skills")
json_results[["skills"]]
json_results[["skills"]][2]
json_results[["skills"]][c("technical skills")]
json_results[["skills"]][c("technical skills", "soft skills")]
json_results[["technical skills"]][c("technical skills")]
json_results[["technical skills"]]
map_dfr(json_results, extract, "technical skills")
map_dfr(json_results, extract, "skills")
##This chunk is concerned with getting the API function working
## Write a function to get any given page. After that I can just iterate while there are still jobs to find :)
get_adzuna_api <- function(api_id, api_key, page,
key_words = c("data", "analyst"), country = "ch") { #API ID and key are variables, so that they can remain secret
key_words <- stringr::str_c(key_words[1], "%20", key_words[2]) #Can only take two key words. All needed for most data professions
api_call_string <- stringr::str_c("http://api.adzuna.com/v1/api/jobs/",
country, "/search/", page, "?app_id=",
api_id, "&app_key=", api_key,
"&results_per_page=20&what=", key_words,
"&max_days_old=730&salary_include_unknown=1&content-type=application/json")
api_return <- GET(api_call_string)
api_return_text <- content(api_return, "text")
api_return_df <- jsonlite::fromJSON(api_return_text)
api_return_df$results
}
## This code block is about removing unwanted columns from the APi response and renaming other ones.
## Functionalizing for easier integration into the automated pipeline downstream
clean_adzuna_response <- function(adzuna_response) {
response_cleaned <- data.frame(
date_posted = adzuna_response$created,
job_title = adzuna_response$title,
company = adzuna_response$company$display_name,
location = adzuna_response$location$display_name,
website = adzuna_response$redirect_url
) %>%
filter(str_detect(website, "details")) #Adzuna links quite a few instances of external job boards
response_cleaned
}
### At first, this will be a mess of re-learning how to web scrape :P
parse_adzuna_data <- function (adzuna_http){
adzuna_html_response <- read_html(adzuna_http) #Get the website
adzuna_body <- adzuna_html_response %>% #Extract the body of the job ad
html_nodes(".adp-body") %>%
html_text()
adzuna_body
}
reticulate::repl_python()
execute_scrape_and_prompt <- function (adzuna_address){
adzuna_raw_return <- parse_adzuna_data(adzuna_address)
py$summarize_adzuna(adzuna_raw_return) ## The py$ calls from the python side of the environment
}
adzuna_api_returns_14jul23 <- readRDS("adzuna_api_returns_14jul23.rds")
execute_scrape_and_prompt(adzuna_api_returns_14jul23[1])
execute_scrape_and_prompt(adzuna_api_returns_14jul23$website[1])
test6 <- execute_scrape_and_prompt(adzuna_api_returns_14jul23$website[1])
as_tibble(test6)
fromJSON(test6)
fromJSON(test6) %>%
as_tibble
fromJSON(test6) %>%
as_tibble %>%
unnest()
fromJSON(test6) %>%
select("technical skills")
fromJSON(test6)
fromJSON(test6)[[1]]
fromJSON(test6)[[1]][1]
fromJSON(test6)[[1]][2]
fromJSON(test6)[[1]][[2]]
soft_skills <- c()
tech_skills <- c()
qualifications <- c()
for (i in 1:4) {
try({   ###The try function is here in case any web scrape fails
json_return <- execute_scrape_and_prompt(
adzuna_api_returns_14jul23$website[i]
)
soft_skills <- c(soft_skills, fromJSON(json_return)[[1]][[1]])
tech_skills <- c(tech_skills, fromJSON(json_return)[[1]][[2]])
qualifications <- c(qualifications, fromJSON(json_return[[1]][[3]]))
}, silent = TRUE
)
Sys.sleep(30) ## Given the time to webscrape and call GPT this should be redundant... but lets be polite.
}
fromJSON(test6)[[1]][[3]]
test7 <- c()
flatten(test6)
fromJSON(test6) %>% flatten()
fromJSON(test6) %>% as_tibble
fromJSON(test6) %>% as_tibble()
fromJSON(test6) %>% as_tibble() %>%unnest()
fromJSON(test6) %>% as_tibble() %>% unnest() %>% pull(skills)
skills <- c()
for (i in 1:4) {
try({   ###The try function is here in case any web scrape fails
json_return <- execute_scrape_and_prompt(
adzuna_api_returns_14jul23$website[i]
)
skills_from_return <- json_return %>%
fromJSON() %>%
as_tibble() %>%
pull("skills")
skills <- c(skills, skills_from_return)
}, silent = TRUE
)
Sys.sleep(30) ## Given the time to webscrape and call GPT this should be redundant... but lets be polite.
}
fromJSON(test6) %>% as_tibble() %>% unnest() %>% pull(skills)
skills <- c()
for (i in 1:2) {
try({   ###The try function is here in case any web scrape fails
json_return <- execute_scrape_and_prompt(
adzuna_api_returns_14jul23$website[i]
)
skills_from_return <- json_return %>%
fromJSON() %>%
as_tibble(cols = c(skills)) %>%
pull(skills) ##This will flatten the information on tech, soft skills and qualifications. Having said that: 1) reviewing the test data, GPT got confused a lot of time about those; 2) We don't strictly need those.
skills <- c(skills, skills_from_return)
}, silent = TRUE
)
Sys.sleep(30) ## Given the time to webscrape and call GPT this should be redundant... but lets be polite.
}
fromJSON(test6) %>% as_tibble() %>% unnest(cols = c(skills)) %>% pull(skills)
for (i in 1:2) {
try({   ###The try function is here in case any web scrape fails
json_return <- execute_scrape_and_prompt(
adzuna_api_returns_14jul23$website[i]
)
skills_from_return <- json_return %>%
fromJSON() %>%
as_tibble(cols = c(skills)) %>%
unnest() %>%
pull(skills) ##This will flatten the information on tech, soft skills and qualifications. Having said that: 1) reviewing the test data, GPT got confused a lot of time about those; 2) We don't strictly need those.
skills <- c(skills, skills_from_return)
}, silent = TRUE
)
Sys.sleep(30) ## Given the time to webscrape and call GPT this should be redundant... but lets be polite.
}
skills <- c()
for (i in 1:2) {
try({   ###The try function is here in case any web scrape fails
json_return <- execute_scrape_and_prompt(
adzuna_api_returns_14jul23$website[i]
)
skills_from_return <- json_return %>%
fromJSON() %>%
as_tibble() %>%
unnest(cols = c(skills)) %>%
pull(skills) ##This will flatten the information on tech, soft skills and qualifications. Having said that: 1) reviewing the test data, GPT got confused a lot of time about those; 2) We don't strictly need those.
skills <- c(skills, skills_from_return)
}, silent = TRUE
)
Sys.sleep(30) ## Given the time to webscrape and call GPT this should be redundant... but lets be polite.
}
skills
skills <- c()
for (i in 3:4) {
try({   ###The try function is here in case any web scrape fails
json_return <- execute_scrape_and_prompt(
adzuna_api_returns_14jul23$website[i]
)
skills_from_return <- json_return %>%
fromJSON() %>%
as_tibble() %>%
unnest(cols = c(skills)) %>%
pull(skills) ##This will flatten the information on tech, soft skills and qualifications. Having said that: 1) reviewing the test data, GPT got confused a lot of time about those; 2) We don't strictly need those.
skills <- c(skills, skills_from_return)
}, silent = TRUE
)
Sys.sleep(30) ## Given the time to webscrape and call GPT this should be redundant... but lets be polite.
}
