import openai
import os
import time
##COMMENT UP THIS CODE!!!
with open('/home/pete/Documents/gpt_key.txt') as t:
openai.api_key = t.readlines()[0].strip("\n")
def get_completion(prompt, model="gpt-3.5-turbo", temperature = 0):
messages = [{"role": "user", "content": prompt}]
response = openai.ChatCompletion.create(
model=model,
messages=messages,
temperature=temperature, # this is the degree of randomness of the model's output
)
return response.choices[0].message["content"]
get_completion("Can you please tell me if I'm connected to GPT?")
adzuna_description = r.test_vector[1]
View(adzuna_description)
print(adzuna_description)
### Now lets pass a job description to Chat GPT and build a prompt
adzuna_description = r.test_vector[2]
print(adzuna_description)
### Now lets pass a job description to Chat GPT and build a prompt
adzuna_description = r.test_vector[5]
print(adzuna_description)
### Now lets pass a job description to Chat GPT and build a prompt
adzuna_description = r.test_vector[3]
print(adzuna_description)
### Now lets pass a job description to Chat GPT and build a prompt
adzuna_description = r.test_vector[4]
print(adzuna_description)
### Now lets pass a job description to Chat GPT and build a prompt
adzuna_description = r.test_vector[7]
print(adzuna_description)
adzuna_summary = get_completion(
"Dear Chat GPT, could you please translate any non-English sections of the text in square brackets into English? [" + adzuna_description +"]"
)
print(adzuna_summary)
library(tidyverse)
library(jsonlite)
library(rvest)
library(reticulate)
##This chunk is concerned with getting the API function working
## Write a function to get any given page. After that I can just iterate while there are still jobs to find :)
get_adzuna_api <- function(api_id, api_key, page,
key_words = c("data", "analyst"), country = "ch") { #API ID and key are variables, so that they can remain secret
key_words <- stringr::str_c(key_words[1], "%20", key_words[2]) #Can only take two key words. All needed for most data professions
api_call_string <- stringr::str_c("http://api.adzuna.com/v1/api/jobs/",
country, "/search/", page, "?app_id=",
api_id, "&app_key=", api_key,
"&results_per_page=20&what=", key_words,
"&max_days_old=730&salary_include_unknown=1&content-type=application/json")
api_return <- GET(api_call_string)
api_return_text <- content(api_return, "text")
api_return_df <- jsonlite::fromJSON(api_return_text)
api_return_df$results
}
## Test the function
test <- get_adzuna_api(
readLines("/home/pete/Documents/adzuna_api.txt")[1],
readLines("/home/pete/Documents/adzuna_api.txt")[2], 10)
library(httr)
library(tidyverse)
library(jsonlite)
library(rvest)
library(reticulate)
##This chunk is concerned with getting the API function working
## Write a function to get any given page. After that I can just iterate while there are still jobs to find :)
get_adzuna_api <- function(api_id, api_key, page,
key_words = c("data", "analyst"), country = "ch") { #API ID and key are variables, so that they can remain secret
key_words <- stringr::str_c(key_words[1], "%20", key_words[2]) #Can only take two key words. All needed for most data professions
api_call_string <- stringr::str_c("http://api.adzuna.com/v1/api/jobs/",
country, "/search/", page, "?app_id=",
api_id, "&app_key=", api_key,
"&results_per_page=20&what=", key_words,
"&max_days_old=730&salary_include_unknown=1&content-type=application/json")
api_return <- GET(api_call_string)
api_return_text <- content(api_return, "text")
api_return_df <- jsonlite::fromJSON(api_return_text)
api_return_df$results
}
## Test the function
test <- get_adzuna_api(
readLines("/home/pete/Documents/adzuna_api.txt")[1],
readLines("/home/pete/Documents/adzuna_api.txt")[2], 10)
test$location$display_name
## This code block is about removing unwanted columns from the APi response and renaming other ones.
## Functionalizing for easier integration into the automated pipeline downstream
clean_adzuna_response <- function(adzuna_response) {
response_cleaned <- data.frame(
date_posted = adzuna_response$created,
job_title = adzuna_response$title,
company = adzuna_response$company$display_name,
location = adzuna_response$location$display_name,
website = adzuna_response$redirect_url
) %>%
filter(str_detect(website, "details")) #Adzuna links quite a few instances of external job boards
response_cleaned
}
##Test clean_adzuna_response
test2 <- clean_adzuna_response(test)
write_csv(test2, "test_returns.csv")
##Lets get a URL to visit
test2 <- read_csv("test_returns.csv")
test2$website[4]
### At first, this will be a mess of re-learning how to web scrape :P
parse_adzuna_data <- function (adzuna_http){
adzuna_html_response <- read_html(adzuna_http) #Get the website
adzuna_body <- adzuna_html_response %>% #Extract the body of the job ad
html_nodes(".adp-body") %>%
html_text()
adzuna_body
}
##Get a return to work with for dev
test3 <- parse_adzuna_data(test2$website[1])
test3
test2$website[1]
##Get a return to work with for dev
test3 <- parse_adzuna_data(test2$website[2])
test3
reticulate::repl_python()
##Get a return to work with for dev
test3 <- parse_adzuna_data(test2$website[2])
test3
##Get a return to work with for dev
test3 <- parse_adzuna_data(test2$website[3])
test3
reticulate::repl_python()
##Get a return to work with for dev
test3 <- parse_adzuna_data(test2$website[1])
test3
reticulate::repl_python()
##Get a return to work with for dev
test3 <- parse_adzuna_data(test2$website[2])
test3
reticulate::repl_python()
